\documentclass{classrep}
\usepackage{color}
\usepackage{url}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage[T1]{fontenc}
\usepackage{polski}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\graphicspath{ {./rys/} }

\usepackage{etoolbox}
\let\bbordermatrix\bordermatrix
\patchcmd{\bbordermatrix}{8.75}{4.75}{}{}
\patchcmd{\bbordermatrix}{\left(}{\left[}{}{}
\patchcmd{\bbordermatrix}{\right)}{\right]}{}{}

\studycycle{Informatyka, studia dzienne, I st.}
\coursesemester{VI}

\coursename{Komputerowe systemy rozpoznawania}
\courseyear{2019/2020}

\courseteacher{dr inż. Marcin Kacprowicz}
\coursegroup{poniedziałek, 12:00}

\author{
  \studentinfo{Radosław Grela}{216769} \and
  \studentinfo{Jakub Wąchała}{216914} 
}

\title{Zadanie 1: ekstrakcja cech, miary podobieństwa, klasyfikacja}
\svnurl{https://github.com/Bonniu/KSR}

\begin{document}
\maketitle

\section{Cel} % Cel
Celem naszego zadania było stworzenie aplikacji do klasyfikacji tekstów za pomocą metody k-NN (k najbliższych sąsiadów) oraz
różnych metryk i miar podobieństwa, a następnie porównać kategorie z tymi wygenerowanymi przez aplikację.

\section{Wprowadzenie} % Wprowadzenie
Głównym zagadnieniem projektowym, z którym mieliśmy do czynienia w ramach zadania 1 była klasyfikacja statystyczna tekstów na podstawie wektora wyekstrahowanych cech. Do przeprowadzenie eksperymentu zaimplementowaliśmy algorytm \textsl{k-najbliższych sąsiadów}.

Algorytm k-najbliższych sąsiadów \textsl{(k-NN - k-nearest neighbors)} to jeden z algorytmów zaliczanych do grupy algorytmów leniwych. Jest to taka grupa algorytmów, która szuka rozwiązania dopiero, gdy pojawia się wzorzec testujący. Przechowuje wzorce uczące, a dopiero później wyznacza się odległość wzorca testowego względem wzorców treningowych. \cite{leniwy} 

Algorytm ten działa w taki sposób, że dla każdego wzorca testowego obliczana jest odległość za pomocą wybranej metryki względem wzorców treningowych, a następnie wybierana jest k najbliższych wzorców treningowych. Wynik wyznaczony jest jako najczęstszy element wśród nich. W naszym zadaniu odległość ta jest równa skali podobieństwa tekstów, a im ta odległość jest mniejsza, tym lepiej.
% cechy
%Stosunek słów kluczowych do wszystkich słów w pierwszych 10% tekstu
%Stosunek słów kluczowych do wszystkich słów w ostatnich 10% tekstu
%Stosunek słów kluczowych do wszystkich słów w dokumencie
%Stosunek słów kluczowych gdzie ilość liter (0,4] do wszystkich słów
%Stosunek słów kluczowych do wszystkich słów gdzie ilość liter słów kluczowych 8+
%Stosunek linii do ilości akapitów
%Stosunek słów o długości >6 do wszystkich słów
%Stosunek słów o długości <=6 do wszystkich słów
%Ilość słów unikalnych
%Ilość słów, których długość wynosi [5,8]
%Najczęściej występujące słowo kluczowe
\subsection{Ekstrakcja cech}
Do ekstrakcji cech charakterystycznych tekstu utworzyliśmy wektor cech, który opisuje tekst za pomocą 11 cech. Liczba słów zawsze jest liczona po zastosowaniu stop-listy oraz stemizacji, bez znaków przestankowych.
\begin{itemize}
\item[•] $C_1$ - Stosunek słów kluczowych do wszystkich słów w pierwszych 10\% tekstu. Obliczona jest za pomocą wzoru:
\begin{equation} C_1 = s_{k10} / s_{10}  \end{equation} gdzie \\
$s_{k10}$ - liczba słów kluczowych, \\
$s_{10}$ - liczba wszystkich słów w pierwszych 10\% tekstu. \\
Przed normalizacją cecha $C_{1}$ zawierała się w wartościach $\in [0,1]$.
\item[•] $C_2$ - Stosunek słów kluczowych do wszystkich słów w ostatnich 10\% tekstu. Obliczona jest za pomocą wzoru:
\begin{equation} C_2 = s_{k90} / s_{90}  \end{equation} gdzie \\
$s_{k90}$ - liczba słów kluczowych, \\
$s_{90}$ - liczba wszystkich słów w ostatnich 10\% tekstu.\\
Przed normalizacją cecha $C_{2}$ zawierała się w wartościach $\in [0,0.5]$.
\item[•] $C_3$ - Stosunek słów kluczowych do wszystkich słów w dokumencie. Obliczona jest za pomocą wzoru:
\begin{equation} C_3 = s_k / s  \end{equation} gdzie \\
$s_k$ - liczba słów kluczowych,\\
$s$ - liczba wszystkich słów w dokumencie. \\
Przed normalizacją cecha $C_{3}$ zawierała się w wartościach $\in [0,0.155]$.
\item[•] $C_4$ - Stosunek słów kluczowych, których ilość liter $\in$ (0,4] do wszystkich słów w dokumencie. Obliczona jest za pomocą wzoru:
\begin{equation} C_4 = s_k / s  \end{equation} gdzie \\
$s_k$ - liczba słów kluczowych, których ilość liter $\in$ (0,4], \\
$s$ - liczba wszystkich słów w dokumencie.\\
Przed normalizacją cecha $C_{4}$ zawierała się w wartościach $\in [0,0.075]$.
\item[•] $C_5$ - Stosunek słów kluczowych, których ilość liter jest $\geq$8 do wszystkich słów w dokumencie. Obliczona jest za pomocą wzoru:
\begin{equation} C_5 = s_k / s  \end{equation} gdzie \\
$s_k$ - liczba słów kluczowych, \\
$s$ - liczba wszystkich słów w dokumencie. \\
Przed normalizacją cecha $C_{5}$ zawierała się w wartościach $\in [0,0.1]$.
\item[•] $C_6$ - Stosunek linii do ilości akapitów. Obliczona jest za pomocą wzoru:
\begin{equation} C_6 = l / a  \end{equation} gdzie \\
$l$ - liczba linii,\\
$a$ - liczba akapitów.\\
Przed normalizacją cecha $C_{6}$ zawierała się w wartościach $\in [1,14]$.
\item[•] $C_7$ - Stosunek słów, których ilość liter jest większa niż 6 do wszystkich słów. Obliczona jest za pomocą wzoru:
\begin{equation} C_7 = s_6 / s  \end{equation} gdzie \\
$s_6$ - liczba słów których ilość liter jest większa niż 6, \\
$s$ - liczba wszystkich słów w dokumencie.\\
Przed normalizacją cecha $C_{7}$ zawierała się w wartościach $\in [0,0.591]$.
\item[•] $C_8$ - Stosunek słów kluczowych, których ilość liter jest $\leq$6 do wszystkich słów w dokumencie. Obliczona jest za pomocą wzoru:
\begin{equation} C_8 = s_{6m} / s  \end{equation} gdzie \\
$s_{6m}$ - liczba słów kluczowych, których ilość liter jest $\leq$6, \\
$s$ - liczba wszystkich słów w dokumencie. \\
Przed normalizacją cecha $C_{8}$ zawierała się w wartościach $\in [0.409,1]$.
\item[•] $C_9$ - Ilość słów unikalnych. Jest to liczba słów, które wystąpiły w tekście co najmniej raz. Przykładowo, dla zdania \textsl{,,Być albo nie być''} ilość słów unikalnych jest równa 3 (\textsl{być, albo, nie}).\\
Przed normalizacją cecha $C_{9}$ przyjmuje wartości $\in [1,420]$.
\item[•] $C_{10}$ - Ilość słów, których ilość liter $\in$ [5,8]. Pseudokod obliczający wartość cechy $C_{10}$:
\textsl{
\begin{itemize}
\item $C_{10}$=0
\item Dla każdego słowa w artykule:
	\begin{itemize}
	\item Jeżeli długość słowa>=5 i długość słowa <=8:
		\begin{itemize}
		\item $C_{10}$++;
		\end{itemize}
	\end{itemize}
\item Zwróć $C_{10}$
\end{itemize}
} 
Przed normalizacją cecha $C_{10}$ zawierała się w wartościach $\in [1,574]$.
\item[•] $C_{11}$ - Najczęściej występujące słowo kluczowe. Jest to cecha tekstowa, której podobieństwo z innym słowem mierzymy jedną z dwóch miar podobieństwa ciągów znaków opisanych w sekcji \textsl{Metryki i miary podobieństwa}.
\end{itemize}

%Czy np. im tekst dłuższy, tym bardziej związany z etykietą USA lub CANADA? (istotne!)}

\subsection{Wyznaczanie słów kluczowych}
Wyznaczenie słów kluczowych przebiega w następujący sposób: na początek za pomocą klasy WordCounter zliczane są wszystkie słowa w artykułach oraz jednocześnie dodawane do odpowiednich list w tej klasie. Każda zmienna jest listą stringów o nazwie wordCountDictionary + nazwa kraju. Dodatkowo, przechowywany jest słownik typu \textsl{<string, int>}, którego kluczem jest słowo, a wartość to ilość wystąpień tego słowa we wszystkich artykułach. Po podliczeniu wszystkich słów oraz przydzieleniu do odpowiednich list wybieramy po 18 najpopularniejszych słów dla każdego kraju, które występują tylko w tym jednym konkretnym kraju. Na koniec $18*6 = 108$ słów zostaje słowami kluczowymi. Cały proces wyznaczania słów kluczoywch jest dokonywany po zastosowaniu stop-listy oraz po stemizacji. Ponadto, proces wybierania słów kluczowych pomija 20\% wszystkich podliczonych słów, aby proces dopasowywania słów kluczowych do krajów nie trwał zbyt długo.
\subsection{Metryki i miary podobieństwa}
Do liczenia odległości pomiędzy artykułami oraz obliczenia miary podobieństwa używaliśmy 3 metryk i 2 miar podobieństwa ciągów tekstowych.
\begin{enumerate}
\item Metryka Euklidesowa - aby obliczyć odległość $d_e(x,y)$ między wektorami x i y należy obliczyć pierwiastek kwadratowy z sumy kwadratów różnic wartości współrzędnych wektora o tych samych indeksach. Wzór jest następujący \cite{euc}:
\begin{equation} 
d_e(x,y)=\sqrt{(x_1-y_1)^2+\ldots+(x_n-y_n)^2}
\end{equation} gdzie $x_i$ i $y_i$ to cechy wektora.
\item Metryka Manhattan - odległość $d_m(x,y)$ jest równa sumie wartości bezwzględnych z różnic wartości współrzędnych wektora o tych samych indeksach \cite{manh}:
\begin{equation} 
d_m(x,y)=\sum_{n=1}^{N} |{x_n-y_n}|
\end{equation} gdzie $x_i$ i $y_i$ to cechy wektora.
\item Metryka Czebyszewa - odległość $d_c(x,y)$ w tej metryce jest równa maksymalnej wartości bezwględnych różnic współrzędnych punktów x oraz y, zgodnie ze wzorem \cite{cze}:
\begin{equation} 
d_c(x,y)=\max_{i} |{x_i-y_i}|
\end{equation} gdzie $x_i$ i $y_i$ to cechy wektora.
\item Miara \textsl{n}-gramów - metoda ta określa podobieństwo łańcuchów tekstowych $s_1$, $s_2$ w oparciu o ilość wspólnych podciągów n-elementowych, czyli \textsl{n}-gramów \cite{wyklad}:
\begin{equation}
sim_n(s_1, s_2) = \frac{1}{N-n+1} \sum_{i=1}^{N-n+1} h(i)
\end{equation} gdzie 

$h(i) = 1$, jeśli n-elementowy podciąg zaczynający się od i-tej pozycji w $s_1$ występuje co najmniej raz w  $s_2$, w przeciwnym razie $h(i) = 0$

$N-n+1$ - ilość możliwych n-elemenetowych podciągów w $s_1$.

W naszym programie n jest stałe i wynosi 3.
\item Uogólniona miara \textsl{n-gramów} (Miara Niewiadomskiego) - ta miara jest ulepszoną wersją miary n-gramów. Bada ona podobieństwo poprzez sprawdzenie podciągów różnej długości od jedno- do N-elementowych, gdzie N jest długością słowa  \cite{wyklad}:
\begin{equation}
\mu_N(s_1, s_2) = \frac{2}{N^2+N} \sum_{i=1}^{N(s_1)} \sum_{j=1}^{N(s_1)-i+1} h(i,j)
\end{equation} gdzie

$h(i,j) = 1$, jeśli $i$-elementowy podciąg w słowie $s_1$ zaczynający się od $j$-tej pozycji w słowie $s_1$ pojawia się co najmniej raz w  słowie $s_2$, w przeciwnym razie $h(i,j) = 0$

$N(s_1), N(s_2)$ – ilość liter w słowach $s_1$ i $s_2$;

$N = max\{(s_1), N(s_2)\}$

$\frac{N^2+N}{2}$ - ilość możliwych podciągów od 1-elementowych do $N$-elementowych w słowie o długości $N$.
\end{enumerate}

%\item Miara \textsl{Term Frequency Matrix}, czyli po polsku ,,macierz częstości występowania terminów'' podaje wartość podobieństwa dokumentów $d_1$ i $d_2$ ze względu na wybrany %zbiór terminów, np. słów kluczowych. Ustawiamy macierz słów kluczowych i dokumentów:
%\begin{equation}
%\bbordermatrix{~ & t_1 & t_2 & \ldots & t_n \cr
        %          d_1 & a_{11} & a_{12} & \ldots & a_{1n} \cr
    %              d_2 & a_{21} & a_{22} & \ldots & a_{2n} \cr}
%\end{equation}
%Następnie podobieństwo otrzymanych wektorów jest obliczone przy pomocy amplitudy kosinusowej: 
%\begin{equation}
%r_{ca}(V_1, V_2)= \textsl{$\frac{|\sum_{i=1}^{n} a_{1i}*a_{2i}|}{\sqrt{\sum_{i=1}^{n} a_{1i}^2 * \sum_{i=1}^{n} a_{2i}^2}}$}
%\end{equation}
%\item Odległość Minkowskiego \cite{wyklad} - jest to uogólniony wzór odległości euklidesowej, miejskiej oraz Czebyszewa. Odległość
%$L_m(x,y)$ w tej metryce dla m=3, zgodnie ze wzorem jest równa \cite{minkowski}:
%\begin{equation} 
%L_m(x,y)=\sqrt[m]{|x_1-y_1|^m+\ldots+|x_n-y_n|^m}
%\end{equation}
%Dla m=3, czyli parametru użytego w naszym programie:
%\begin{equation} 
%L_3(x,y)=\sqrt[3]{|x_1-y_1|^3+\ldots+|x_n-y_n|^3}
%\end{equation}
%\item \textsl{Canberra distance} \cite{wyklad} - odległość $d_{can}(x,y)$ w tej metryce jest równa sumie ilorazów wartości bezwględnej %różnicy współrzędnych wektorów x oraz y z sumą wartości bezwzględnych współrzędnych wektorów x oraz y, zgodnie ze wzorem: %\cite{canberra}
%\begin{equation} 
%d_{can}(x,y)=\sum_{n=1}^{N} \frac{|x_n-y_n|}{|x_n|+|y_n|}
%\end{equation}
\subsection{Miary jakości}
W wynikach klasyfikacji używamy następujących miar jakości \cite{apr}:
\begin{itemize}
\item[•] Accuracy:
\begin{equation}
ACC = \frac{TP + TN}{TP + TN + FP + FN}
\end{equation}
\item[•] Precision
\begin{equation}
PPV = \frac{TP}{TP + FP}
\end{equation}
\item[•] Recall
\begin{equation}
TPR = \frac{TP}{TP + FN}
\end{equation}
\end{itemize}
Oznaczenia użytych symboli:

TP - miara prawdziwie pozytywna (\textsl{true positive})

TN - miara prawdziwie negatywna (\textsl{true negative})

FP - miara fałszywie pozytywna (\textsl{false positive})

FN - miara fałszywie negatywna (\textsl{false negative})



\section{Opis implementacji} % Opis implementacji
Nasza aplikacja została utworzona w języku C\# i jest to aplikacja konsolowa. Poniżej opisane zostały wszystkie klasy oraz dane zawarte w naszym projekcie:
\begin{itemize}
\item Klasa Program to klasa główna naszego programu. Jest swego rodzaju kontrolerem dla pozostałych klas. Znajduje się tutaj funkcja \textsl{main}, która rozpoczyna wykonywanie programu.
\item W katalogu \textsl{dane} znajdują się wszystkie pliki z artyukłami, które są wykorzystywane do badań.
\item Klasa Metric jest klasą abstrakcyjną. Odpowiada za obliczenia odległości tekstów. Po tej klasie dziedziczą klasy: EuclideanMetric, ChebyshewMetric oraz ManhattanMetric.
\item Klasa Measure jest klasą abstrakcyjną. Po niej dziedziczą klasy \textsl{GeneralizedNGramsMeasure} i \textsl{NGramsMeasure}, które odpowiadają za obliczanie miar podobieństwa łańcuchów tekstowych.
\item Klasa Feature jest klasą abstrakcyjną. Po niej dziedziczy 10 klas: Feature 1-10, które reprezentują każdą z 10 wyekstrahowanych przez nas cech.
\item Klasa Stemmer to klasa, która odpowiada za stemizację tekstów. Została ona zapożyczona z \cite{stemmer}
\item Klasa StopwordTool jest klasą odpowiedzialną za usuwanie słów znajdujących się na stopliście. Również została znaleziona i zapożyczona z Internetu ze strony \cite{stopword}
\item WordCounter jest używany do zliczania słów wszystkich artykułów i podania ich liczności. Potrzebny głównie do  wyznaczenia słów kluczowych.
\item Klasa KeyWords odpowiada za wyznaczenie 100 słów kluczowych. Metoda wyznaczania słów kluczowych została opisana w sekcji 2.
\item Klasa FileReader odpowiada za otwieranie każdego pliku z artykułami
\item FileParser to klasa odpowiedzialna za parsowanie danych z konkretnego pliku.
\item Article to klasa reprezentująca artykuł. Zawiera takie cechy jak: tekst oryginalny, tekst przetworzony, \textsl{place}, \textsl{classifiedPlace}, wektor cech.
\item Klasa Neighbor to klasa, która przechowuje artykuł oraz obliczoną wartość algorytmu k-NN dla konkretnego, obecnie sprawdzanego artykułu w algorytmie. Wykorzystujemy ją, aby znaleźć najbliższych k sąsiadów.
\item KNN to klasa odpowiedzialna za algorytm k najbliższych sąsiadów. 
\end{itemize}
Na rysunku \ref{uml} przedstawiony został diagram UML naszego programu.
\begin{figure}[h!]
	\centering
	\includegraphics[width=1\textwidth]{uml.png}
	\caption{Diagram UML.}
	\label{uml}
\end{figure}

Na rysunku \ref{exampleRun} przedstawiony został wynik z konsoli po przykładowym uruchomieniu programu.
\begin{figure}[h!]
	\centering
	\includegraphics[width=1\textwidth]{exampleRun.png}
	\caption{Wynik z przykładowego uruchomienia programu.}
	\label{exampleRun}
\end{figure}
\section{Materiały i metody} % Materiały i metody
Wykonana przez nas klasyfikacja została wykonana za pomocą wszystkich trzech metryk oraz dwóch miar podobieństwa. Każdy przypadek testowy był klasyfikowany dla dziesięciu różnych wartości k najbliższych sąsiadów: 2, 3, 4, 5, 7, 10, 13, 15, 20, 25.

Klasyfikacji dokonywaliśmy tylko na tych tekstach, które miały jedną z etykiet: \textsl{west-germany, usa, france, uk, canada, japan} i były to ich jedyne etykiety.

Dokonaliśmy pięciu różnych podziałów na dane testowe oraz treningowe:
\begin{itemize}
\item 30\% dane treningowe, 70\% dane testowe
\item 50\% dane treningowe, 50\% dane testowe
\item 70\% dane treningowe, 30\% dane testowe
\item 80\% dane treningowe, 20\% dane testowe
\item 85\% dane treningowe, 15\% dane testowe
\end{itemize}

Poniżej zostały opisane 4 wykonane przez nas eksperymenty.

\subsection{Badanie zależności Accuracy od parametru k}

W tym eksperymencie badaliśmy wpływ doboru parametru k na Accuracy. Program został uruchomiony dla 10 różnych wartości $k\in$ \{2, 3, 4, 5, 7, 10, 13, 15, 20, 25\}.

Klasyfikacja tekstów została wykonana dla stałej wartości podziału zbioru cech na testowe i treningowe. Był to podział 50\% dane treningowe, 50\% dane testowe.

Metryką, jakiej użyliśmy była metryka Euklidesowa.

\subsection{Badanie zależności Accuracy od wartości proporcji podziału zbioru}

W tym eksperymencie badaliśmy wpływ wartości proporcji podziału zbioru na Accuracy. Program został uruchomiony dla k=10.

Badane podziały były następujące:
\begin{itemize}
	\item 30\% dane treningowe, 70\% dane testowe
	\item 50\% dane treningowe, 50\% dane testowe
	\item 70\% dane treningowe, 30\% dane testowe
	\item 80\% dane treningowe, 20\% dane testowe
	\item 85\% dane treningowe, 15\% dane testowe
\end{itemize}

Metryką, jakiej użyliśmy była metryka Manhattan.

\subsection{Badanie zależności Accuracy od wyboru metryki}

W tym eksperymencie badaliśmy zależność Accuracy od wyboru metryki. Program został uruchomiony dla k=13. Podział na dane treningowe i testowe był stały i wynosił 70\% treningowe i 30\% testowe.

\subsection{Badanie zależności Accuracy od wyboru podzbioru cech}

W tym eksperymencie badaliśmy zależność Accuracy od wyboru podzbioru cech. Program został uruchomiony dla k=20. Metryka, jakiej użyliśmy to metryka Czebyszewa. Podział na dane treningowe i testowe był stały i wynosił 50\% treningowe i 50\% testowe. Podzbiory cech jakie badaliśmy były następujące:
\begin{itemize}
	\item Wszystkie cechy
	\item $C_1, C_2, C_3, C_4, C_5, C_{11}$
	\item $C_6, C_7, C_8, C_9, C_{10}$ 
	\item $C_1, C_2, C_3, C_8, C_9, C_{10}$
	\item $C_4, C_5, C_6, C_7, C_{11}$
\end{itemize}


\newpage
\section{Wyniki} % Wyniki
\subsection{Badanie wyników klasyfikacji w zależności od parametru k}
\begin{table}[h!]
	\centering
	\begin{tabular} {c c}
		\hline
		\textbf{Parametr k} & \textbf{Accuracy [\%]} \\ [0.5ex] 
		\hline
		\hline 
		2 & 67,705 \\ 
		3 & 73,921 \\
		4 & 74,900 \\
		5 & 76,799 \\
		7 & 78,312 \\
		10 & 79,024 \\
		13 & 79,365 \\
		15 & 79,410 \\
		20 & 79,632 \\
		25 & 79,795 \\
		\hline
	\end{tabular}
	\caption{Zależność Accuracy od wartości k. }
\end{table}

\begin{figure}[h!]
	\centering
	\includegraphics[width=1\textwidth]{accuracyK.png}
	\caption{Wykres przedstawiający zależność Accuracy od wartości k (dane treningowe/testowe 50\%/50\%, Metryka Euklidesowa).}
	\label{accuracyK}
\end{figure}

\newpage
\subsection{Badanie wyników klasyfikacji w zależności od podziału na dane treningowe i testowe}
\begin{table}[h!]
	\centering
	\begin{tabular} {c c}
		\hline
		\textbf{Dane treningowe/testowe} & \textbf{Accuracy [\%]} \\ [0.5ex] 
		\hline
		\hline 
		30/70 & 78,325 \\ 
		50/50 & 78,979 \\
		70/30 & 81,409 \\
		80/20 & 82,911 \\
		85/15 & 83,667 \\
		\hline
	\end{tabular}
	\caption{Zależność Accuracy od pięciu wartości proporcji podziału zbioru dla k=10. }
\end{table}

\begin{figure}[h!]
    \centering
    \includegraphics[width=1\textwidth]{accuracyTT.png}
    \caption{Wykres przedstawiający zależność Accuracy od pięciu wartości proporcji podziału zbioru, k=10, metryka Manhattan.}
    \label{accuracyTT}
\end{figure}

\newpage
\subsection{Badanie zależności Accuracy od wyboru metryki}

\begin{table}[h!]
	\centering
	\begin{tabular} {c c}
		\hline
		\textbf{Metryka} & \textbf{Accuracy [\%]} \\ [0.5ex] 
		\hline
		\hline 
		Euklidesowa & 81,409 \\ 
		Czebyszewa & 81,335 \\
		Manhattan & 81,384 \\
		\hline
	\end{tabular}
	\caption{Zależność Accuracy od wyboru metryki dla k=13 i podziału 70/30. }
\end{table}

\begin{figure}[h!]
    \centering
    \includegraphics[width=1\textwidth]{accuracyMetric.png}
    \caption{Wykres przedstawiający zależność Accuracy od wyboru metryki dla k=13 i podziału 70/30.}
    \label{accuracyMetric}
\end{figure}

\newpage
\subsection{Badanie różnic w wyborze podzbioru cech}
\begin{table}[h!]
	\centering
	\begin{tabular} {c c}
		\hline
		\textbf{Podzbiór cech} & \textbf{Accuracy [\%]} \\ [0.5ex] 
		\hline
		\hline 
		Wszystkie cechy & 79,573 \\ 
		$C_1, C_2, C_3, C_4, C_5, C_{11}$ & 79,81 \\
		$C_6, C_7, C_8, C_9, C_{10}$ & 79,558 \\
		$C_1, C_2, C_3, C_8, C_9, C_{10}$ & 79,662 \\
		$C_4, C_5, C_6, C_7, C_{11}$ & 79,78 \\
		\hline
	\end{tabular}
	\caption{Zależność Accuracy od wyboru podzbioru cech dla k=20, podziału 50/50 i metryki Czebyszewa. }
\end{table}

\begin{figure}[h!]
    \centering
    \includegraphics[width=1\textwidth]{accuracyFeatures.png}
    \caption{Wykres przedstawiający zależność Accuracy od wyboru podzbioru cech, k=20, podział 50/50, metryka Czebyszewa.}
    \label{accuracyFeatures}
\end{figure}

\newpage
\section{Dyskusja} % Dyskusja
{\color{blue}
Sekcja ta powinna zawierać dokładną interpretację uzyskanych wyników
eksperymentów wraz ze szczegółowymi wnioskami z nich płynącymi. Najcenniejsze
są, rzecz jasna, wnioski o charakterze uniwersalnym, które mogą być istotne
przy innych, podobnych zadaniach. Należy również omówić i wyjaśnić wszystkie
napotakane problemy (jeśli takie były). Każdy wniosek powinien mieć poparcie
we wcześniej przeprowadzonych eksperymentach (odwołania do konkretnych
wyników). Jest to jedna z najważniejszych sekcji tego sprawozdania, gdyż
prezentuje poziom zrozumienia badanego problemu.}
\section{Wnioski}
{\color{blue}W tej, przedostatniej, sekcji należy zamieścić podsumowanie
najważniejszych wniosków z sekcji poprzedniej. Najlepiej jest je po prostu
wypunktować. Znów, tak jak poprzednio, najistotniejsze są wnioski o
charakterze uniwersalnym.}


\begin{thebibliography} {0}
\bibitem{anbook} Niewiadomski, Adam. Methods for the Linguistic Summarization of Data: Applications of Fuzzy Sets and Their Extensions. Akademicka Oficyna Wydawnicza EXIT. Warszawa, 2008. ISBN 978-83-60434-40-6
\bibitem{wyklad} \textsl{https://ftims.edu.p.lodz.pl/pluginfile.php/132368/mod\_folder/content/0/
ksr-wyklad-2009.pdf?forcedownload=1} [dostęp 22.03.2020]
\bibitem{manh} \textsl{https://en.wikipedia.org/wiki/Taxicab\_geometry} [dostęp 01.04.2020]
\bibitem{cze} \textsl{https://en.wikipedia.org/wiki/Chebyshev\_distance} [dostęp 01.04.2020]
\bibitem{euc} \textsl{https://en.wikipedia.org/wiki/Euclidean\_distance} [dostęp 01.04.2020]
\bibitem{stemmer} \textsl{https://tartarus.org/martin/PorterStemmer/csharp.txt} [dostęp 22.03.2020]
\bibitem{stopword} \textsl{https://www.dotnetperls.com/stopword-dictionary} [dostęp 22.03.2020]
\bibitem{leniwy} \textsl{http://home.agh.edu.pl/~horzyk/lectures/miw/KNN.pdf} [dostęp 22.03.2020]
\bibitem{apr} \textsl{https://pl.wikipedia.org/wiki/Tablica\_pomy\%C5\%82ek} [dostęp 01.04.2020]
\end{thebibliography}
\end{document}
